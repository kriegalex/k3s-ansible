---
- name: Verify target storage class exists
  kubernetes.core.k8s_info:
    api_version: storage.k8s.io/v1
    kind: StorageClass
    name: "{{ target_storage_class }}"
  register: sc_check
  failed_when: sc_check.resources | length == 0
  when: target_storage_class is defined

- name: Generate unique suffix for temporary PVCs
  ansible.builtin.set_fact:
    temp_suffix: "{{ 999999 | random | string }}"

- name: Scale down target deployments
  kubernetes.core.k8s_scale:
    api_version: apps/v1
    kind: "{{ item.kind }}"
    name: "{{ item.name }}"
    namespace: "{{ k8up_default_namespace }}"
    replicas: 0
    wait: true
    wait_timeout: 300
  loop:
    - { kind: Deployment, name: "{{ k8up_nextcloud_release }}" }

- name: Enable maintenance mode on PostgreSQL cluster
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: postgresql.cnpg.io/v1
      kind: "{{ item.kind }}"
      metadata:
        name: "{{ item.name }}"
        namespace: "{{ k8up_default_namespace }}"
      spec:
        nodeMaintenanceWindow:
          inProgress: true
          reusePVC: true  # This allows us to reuse the PVC
  loop:
    - { kind: Cluster, name: "{{ restore_postgresql_cluster_name }}" }

- name: Create temporary PVCs for restore
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: "{{ item.name }}-temp-{{ temp_suffix }}"
        namespace: "{{ k8up_default_namespace }}"
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: "{{ target_storage_class | default(item.original_sc) }}"
        resources:
          requests:
            storage: "{{ item.size }}"
  loop:
    - { name: "{{ restore_nextcloud_config_pvc }}", size: "{{ restore_nextcloud_config_size }}", original_sc: "{{ original_storage_class | default('local-path') }}" }
    - { name: "{{ restore_postgresql_data_pvc }}", size: "{{ restore_postgresql_data_size }}", original_sc: "{{ original_storage_class | default('local-path') }}" }

- name: Create Restore
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: k8up.io/v1
      kind: Restore
      metadata:
        name: "restore-{{ backup_name }}"
        namespace: "{{ k8up_default_namespace }}"
      spec:
        backend:
          repoPasswordSecretRef:
            name: minio-credentials
            key: password
          s3:
            endpoint: "{{ minio_endpoint }}"
            bucket: "{{ minio_bucket }}"
            accessKeyIDSecretRef:
              name: minio-credentials
              key: username
            secretAccessKeySecretRef:
              name: minio-credentials
              key: password
        restore:
          snapshot: "latest"
          persistentVolumeClaims:
            - sourcePVC: "{{ backup_nextcloud_config_pvc }}"
              targetPVC: "{{ restore_nextcloud_config_pvc }}-temp-{{ temp_suffix }}"
            - sourcePVC: "{{ backup_postgresql_data_pvc }}"
              targetPVC: "{{ restore_postgresql_data_pvc }}-temp-{{ temp_suffix }}"
        podSecurityContext:
          runAsUser: 1000
          runAsGroup: 1000

- name: Wait for restore completion
  kubernetes.core.k8s_info:
    api_version: k8up.io/v1
    kind: Restore
    name: "restore-{{ backup_name }}"
    namespace: "{{ k8up_default_namespace }}"
  register: restore_status
  until:
    - restore_status.resources[0].status is defined
    - restore_status.resources[0].status.started is defined
    - restore_status.resources[0].status.finished is defined
  retries: 60
  delay: 30

- name: Verify restore success
  ansible.builtin.fail:
    msg: "Restore failed: {{ restore_status.resources[0].status.failed }}"
  when: restore_status.resources[0].status.failed is defined

- name: Wait for PostgreSQL pods to terminate
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: "{{ k8up_default_namespace }}"
    label_selectors:
      - "postgresql={{ restore_postgresql_cluster_name }}"
  register: pg_pods
  until: pg_pods.resources | length == 0
  retries: 30
  delay: 10

# Data migration section
- name: Create data migration helper pod
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Pod
      metadata:
        name: "data-migration-{{ temp_suffix }}"
        namespace: "{{ k8up_default_namespace }}"
      spec:
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
          fsGroup: 1000
        containers:
          - name: rsync
            image: instrumentisto/rsync-ssh:alpine3.18
            command: ["sh", "-c", "while true; do sleep 3600; done"]
            volumeMounts:
              - name: source-nextcloud-config
                mountPath: /source/nextcloud-config
              - name: source-postgresql-data
                mountPath: /source/postgresql-data
              - name: target-nextcloud-config
                mountPath: /target/nextcloud-config
              - name: target-postgresql-data
                mountPath: /target/postgresql-data
        volumes:
          - name: source-nextcloud-config
            persistentVolumeClaim:
              claimName: "{{ restore_nextcloud_config_pvc }}-temp-{{ temp_suffix }}"
          - name: source-postgresql-data
            persistentVolumeClaim:
              claimName: "{{ restore_postgresql_data_pvc }}-temp-{{ temp_suffix }}"
          - name: target-nextcloud-config
            persistentVolumeClaim:
              claimName: "{{ restore_nextcloud_config_pvc }}"
          - name: target-postgresql-data
            persistentVolumeClaim:
              claimName: "{{ restore_postgresql_cluster_name }}-1"

- name: Wait for migration pod to be ready
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    name: "data-migration-{{ temp_suffix }}"
    namespace: "{{ k8up_default_namespace }}"
  register: migration_pod
  until: migration_pod.resources[0].status.phase == 'Running'
  retries: 30
  delay: 10

- name: Copy Nextcloud config data
  kubernetes.core.k8s_exec:
    namespace: "{{ k8up_default_namespace }}"
    pod: "data-migration-{{ temp_suffix }}"
    command: >-
      rsync -av --delete /source/nextcloud-config/ /target/nextcloud-config/

- name: Copy PostgreSQL data
  kubernetes.core.k8s_exec:
    namespace: "{{ k8up_default_namespace }}"
    pod: "data-migration-{{ temp_suffix }}"
    command: >-
      rsync -av --delete /source/postgresql-data/ /target/postgresql-data/

- name: Delete migration pod
  kubernetes.core.k8s:
    state: absent
    api_version: v1
    kind: Pod
    name: "data-migration-{{ temp_suffix }}"
    namespace: "{{ k8up_default_namespace }}"

- name: Remove temporary PVCs
  kubernetes.core.k8s:
    state: absent
    api_version: v1
    kind: PersistentVolumeClaim
    name: "{{ item }}-temp-{{ temp_suffix }}"
    namespace: "{{ k8up_default_namespace }}"
  loop:
    - "{{ restore_nextcloud_config_pvc }}"
    - "{{ restore_postgresql_data_pvc }}"

- name: Scale up applications
  kubernetes.core.k8s_scale:
    api_version: apps/v1
    kind: "{{ item.kind }}"
    name: "{{ item.name }}"
    namespace: "{{ k8up_default_namespace }}"
    replicas: 1
    wait: true
    wait_timeout: 300
  loop:
    - { kind: Deployment, name: "{{ k8up_nextcloud_release }}" }

- name: Disable maintenance mode on PostgreSQL cluster
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: postgresql.cnpg.io/v1
      kind: Cluster
      metadata:
        name: "{{ restore_postgresql_cluster_name }}"
        namespace: "{{ k8up_default_namespace }}"
      spec:
        nodeMaintenanceWindow:
          inProgress: false
          reusePVC: false  # Reset to default

- name: Wait for PostgreSQL cluster to be ready
  kubernetes.core.k8s_info:
    api_version: postgresql.cnpg.io/v1
    kind: Cluster
    namespace: "{{ k8up_default_namespace }}"
    name: "{{ restore_postgresql_cluster_name }}"
  register: pg_cluster_status
  until:
    - pg_cluster_status.resources[0].status is defined
    - pg_cluster_status.resources[0].status.phase == "Healthy"
    - pg_cluster_status.resources[0].status.readyInstances is defined
    - pg_cluster_status.resources[0].status.readyInstances > 0
  retries: 30
  delay: 10
